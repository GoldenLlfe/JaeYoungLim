# -*- coding: utf-8 -*-
"""Cifal 10 practice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AgRTINLI4JsfDMRZ0E2Hu72bgmglBBSe
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten,BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.utils.np_utils import to_categorical
from tensorflow.keras.datasets import cifar10
from sklearn.model_selection import train_test_split

#데이터 불러오기
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

#트레인과 테스트에 데이터 할당
x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)

#데이터 정규화
x_train, x_valid, x_test = x_train/255.0,  x_valid/255.0, x_test/255.0
y_train = tf.keras.utils.to_categorical(y_train)
y_valid = tf.keras.utils.to_categorical(y_valid)
y_test = tf.keras.utils.to_categorical(y_test)

import matplotlib.pyplot as plt

# 데이터 시각화
plt.figure(figsize=(10, 10))
for i, img in enumerate(x_train[:8]):
    plt.subplot(2,4,i+1)
    plt.imshow(x_train[i])
plt.show()

# 모델1 설계 (kernel_initializer, callback, Dropout (0.5))
model = Sequential()

# 32채널 커널사이즈 3 Conv2D, relu
model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(32,32,3), padding='same'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

#32
model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(MaxPooling2D())

# 64채널
model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# 64채널
model.add(Conv2D(64, kernel_size=(3, 3),activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(MaxPooling2D())

# 128채널
model.add(Conv2D(128, kernel_size=(3, 3),activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# 128채널
model.add(Conv2D(128, kernel_size=(3, 3),activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(MaxPooling2D())

# FCL
# Flatten()
model.add(Flatten())

# Dense() # 512채널
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.5))

# 마지막 분류
model.add(Dense(10, activation='softmax'))

#모델 summary
model.summary()

modelpath = "./{epoch:02d}-{val_loss:.4f}.h5"
#model1.fit() #EarlyStopping적용 patience=7
callback_list=[tf.keras.callbacks.ModelCheckpoint(filepath=modelpath,
                                                  monitor='val_loss,',
                                                  verbose=1,
                                                  save_best_only=True),
               tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=7)]

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=tf.keras.optimizers.RMSprop(),
              metrics=['accuracy'])
history = model.fit(x_train, y_train,
          batch_size=32,
          epochs=5,
          verbose=1,
          validation_data=(x_valid, y_valid),shuffle=True,callbacks=callback_list)

# 테스트 셋의 오차
y_vloss = history.history['val_loss']

# 학습셋의 오차
y_loss = history.history['loss']

# 그래프로 표현
x_len = np.arange(len(y_loss))
plt.plot(x_len, y_vloss, marker='.', c="red", label='Testset_loss')
plt.plot(x_len, y_loss, marker='.', c="blue", label='Trainset_loss')

# 그래프에 그리드를 주고 레이블을 표시
plt.legend(loc='upper right')
plt.grid()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()

"""# UNDERFITTING 발생"""