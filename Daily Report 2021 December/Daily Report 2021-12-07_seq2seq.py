# -*- coding: utf-8 -*-
"""2021-12-07 seq2seq.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vmkLQiQ2CLRFSvDzwP-kJzlsHGNfEDg9
"""

import tensorflow as tf
from tensorflow.keras import layers, Model
import numpy as np
import matplotlib.pyplot as plt

"""### Tanh을 구현해봅시다."""

class Tanh(Model):
    def call(self, x):
        return 2 / (1 + tf.exp(-2*x)) - 1

x = tf.linspace(-5, 5, 1000)
y = Tanh()(x)

plt.figure(figsize=[8, 3])
plt.title('Tanh')
plt.scatter(x, y, s=1)
plt.grid()
plt.show()

"""### Dense Layer를 구현해봅시다."""

class Dense(Model): 
    def __init__(self, input_dim, output_dim):
        super().__init__()
        self.w = tf.random.normal(shape=(input_dim, output_dim))
        self.b = tf.zeros(shape=(output_dim))
        
    def call(self, x):
        # (batch, input_dim)
        # y = W*x + b
        y = x @ self.w + self.b
        return y

t = tf.random.normal((2, 256)) # x
t = Dense(256, 512)(t)
print(t.shape)

"""### RNNCell을 구현해봅시다.
$h^{\prime}=\tanh \left(W_{i h} x+b_{i h}+W_{h h} h+b_{h h}\right)$
"""

class RNNCell(Model):
    def __init__(self, input_dim, hidden_dim, activation=Tanh):
        super().__init__()
        self.dense_1 = Dense(hidden_dim, hidden_dim)
        self.dense_2 = Dense(input_dim, hidden_dim)
        self.activation = activation()
    
    def call(self, x, h):
        # x : (batch, input_dim)
        h = self.activation(self.dense_2(x)+self.dense_1(h))
        
        return h

x = tf.random.normal((2, 16)) # input dim
h = tf.random.normal((2, 32)) # hidden dim

y = RNNCell(16, 32)(x,h)
print(y.shape)

"""### RNN을 구현해봅시다.

RNN는 RNNCell을 sub-layer로 갖고 있습니다.

forward pass를 구현하는 call에서 for loop 통해 매 time step의 vector를 RNNCell에 넣고 hidden state를 출력합니다.

출력된 hidden state는 다음 time step의 hidden state 입력으로 들어갑니다.

첫번째 time step에서는 주어진 hidden state가 없으므로 tf.zeros를 이용하여 0으로 채운 벡터를 사용합니다.

모든 time step의 출력은 for loop이 끝난 뒤, tf.stack 명령을 통해 쌓아서 최종 출력으로 만듭니다.
"""

class RNN(Model):
    def __init__(self, input_dim, hidden_dim, activation=Tanh):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.rnn_cell = RNNCell(input_dim, hidden_dim, activation)
    
    def call(self, x):
        # x : (batch, length, input_dim)
        batch, length, input_dim = x.shape

        h = tf.zeros((batch, self.hidden_dim)) # 초기 벡터를 0으로 초기화한다.
        y = [] # 결과를 저장할 곳을 초기화 (빈 리스트)
        for l in range(length): # timestep으로 loop
            # batch, length, input_dim
            x_ = x[:, l, :]
            h = self.rnn_cell(x_, h)
            y.append(h)
        y = tf.stack(y, axis=1)
        return y

x = tf.random.normal((2, 100, 16))
y = RNN(16, 32)(x)
print(y.shape)

"""### GRUCell을 구현해봅시다.

\begin{aligned}
&r=\sigma\left(W_{i r} x+b_{i r}+W_{h r} h+b_{h r}\right) \\
&z=\sigma\left(W_{i z} x+b_{i z}+W_{h z} h+b_{h z}\right) \\
&n=\tanh \left(W_{i n} x+b_{i n}+r *\left(W_{h n} h+b_{h n}\right)\right) \\
&h^{\prime}=(1-z) * n+z * h
\end{aligned}
"""

class Sigmoid(Model):
    def call(self, x):
        return 1 / (1 + np.exp(-x))

x = tf.linspace(-5, 5, 1000)
y = Sigmoid()(x)

plt.figure(figsize=[8, 3])
plt.title('Tanh')
plt.scatter(x, y, s=1)
plt.grid()
plt.show()

"""\begin{aligned}
&r=\sigma\left(W_{i r} x+b_{i r}+W_{h r} h+b_{h r}\right) \\
&z=\sigma\left(W_{i z} x+b_{i z}+W_{h z} h+b_{h z}\right) \\
&n=\tanh \left(W_{i n} x+b_{i n}+r *\left(W_{h n} h+b_{h n}\right)\right) \\
&h^{\prime}=(1-z) * n+z * h
\end{aligned}
"""

class GRUCell(Model):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.sigmoid = Sigmoid()
        self.tanh = Tanh()
        self.dense_ir = Dense(input_dim, hidden_dim)
        self.dense_hr = Dense(hidden_dim, hidden_dim)
        self.dense_iz = Dense(input_dim, hidden_dim)
        self.dense_hz = Dense(hidden_dim, hidden_dim)
        self.dense_in = Dense(input_dim, hidden_dim)
        self.dense_hn = Dense(hidden_dim, hidden_dim)

    def call(self, x, h):
        # x : (batch, input_dim)
        # h : (batch, hidden_dim)

        r = self.sigmoid(self.dense_ir(x) + self.dense_hr(h))
        z = self.sigmoid(self.dense_iz(x) + self.dense_hz(h))
        n = self.tanh(self.dense_in(x) + r* self.dense_hn(h))
        h = (1-z) * n + z *h
        return h

x = tf.random.normal((2, 16)) # input dim
h = tf.random.normal((2, 32)) # hidden dim

y = RNNCell(16, 32)(x,h)
print(y.shape)

"""### GRU를 구현해봅시다."""

class GRU(Model):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.gru_cell = GRUCell(input_dim, hidden_dim)
    
    def call(self, x):
        # x : (batch, length, input_dim)
        batch, length, input_dim = x.shape

        h = tf.zeros((batch, self.hidden_dim)) # 초기 벡터를 0으로 초기화한다.
        y = [] # 결과를 저장할 곳을 초기화 (빈 리스트)
        for l in range(length): # timestep으로 loop
            # batch, length, input_dim
            x_ = x[:, l, :]
            h = self.gru_cell(x_, h)
            y.append(h)
        y = tf.stack(y, axis=1)
        return y

x = tf.random.normal((2, 100, 16))
y = GRU(16, 32)(x)
print(y.shape)

"""### LSTM을 구현해봅시다.

\begin{aligned}
&i=\sigma\left(W_{i i} x+b_{i i}+W_{h i} h+b_{h i}\right) \\
&f=\sigma\left(W_{i f} x+b_{i f}+W_{h f} h+b_{h f}\right) \\
&g=\tanh \left(W_{i g} x+b_{i g}+W_{h g} h+b_{h g}\right) \\
&o=\sigma\left(W_{i o} x+b_{i o}+W_{h o} h+b_{h o}\right) \\
&c^{\prime}=f * c+i * g \\
&h^{\prime}=o * \tanh \left(c^{\prime}\right)
\end{aligned}
"""

class LSTMCell(Model):
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.sigmoid = Sigmoid()
        self.tanh = Tanh()
        self.dense = Dense(input_dim + hidden_dim, hidden_dim*4)
    
    def call(self, x, state):
        # x : (batch, input_dim)
        # state : (batch, hidden_dim), (batch, hidden_dim)
        h, c = state

        # (batch, input_dim + hidden_dim)
        xh = np.concatenate([x, h], axis=1)

        # (batch , hidden_dim *4)
        d = self.dense(xh)

        # (batch, hidden_dim), (batch, hidden_dim), (batch, hidden_dim), (batch, hidden_dim)
        i, f, g, o = tf.split(d, 4, axis=1)

        i = self.sigmoid(i)
        f = self.sigmoid(f)
        g = self.tanh(g)
        o = self.sigmoid(o)
        c_ = f*c + i*g
        h_ = o*self.tanh(c_)

        return h_, c_

class LSTM:
    def __init__(self, input_dim, hidden_dim):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.lstm_cell = LSTMCell(input_dim, hidden_dim)
    
    def __call__(self, x):
        # x : (batch, length, input_dim)
        batch, length, input_dim = x.shape

        h = tf.zeros((batch, self.hidden_dim)) # 초기 벡터를 0으로 초기화한다.
        c = tf.zeros((batch, self.hidden_dim))
        y = [] # 결과를 저장할 곳을 초기화 (빈 리스트)
        for l in range(length): # timestep으로 loop
            # batch, length, input_dim
            x_ = x[:, l, :]
            h, c = self.lstm_cell(x_, (h,c))
            y.append(h)
        y = tf.stack(y, axis=1)
        return y

x = tf.random.normal((2, 100, 16))
y = LSTM(16, 32)(x)
print(y.shape)

"""# RNN으로 소설 구현하기"""

import tensorflow as tf
import numpy as np
import os
import time

path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')
print(path_to_file)

with open(path_to_file, 'r') as f:
    lines = f.readlines()
for line in lines:
    print(line.rstrip())

line =' 하이 '
line.rstrip()

"""## 데이터 읽기"""

text = open(path_to_file, 'rb').read().decode(encoding='utf-8')

print('텍스트의 길이 : {}자'.format(len(text)))

print(text[:500])

vocab = sorted(set(text))  #set - 중복된 것들을 제거한다
print('고유 문자 수 {}개'.format(len(vocab)))

for i, u in enumerate(vocab):
    print(i, u)

# 고유 문자에서 인덱스로 매핑 생성
char2idx = {u:i for i, u in enumerate(vocab)}
idx2char = np.array(vocab)

text_as_int = np.array([char2idx[c] for c in text])

print(len(text_as_int))
print(text_as_int[:50])

print('{')
for char,_ in zip(char2idx, range(20)):
    print(' {:4s}: {:3d},'.format(repr(char), char2idx[char]))
print(' ...\n')

# 텍스트에서 처음 13개의 문자가 숫자로 어떻게 매핑되는지 과정
print(' {} --- 문자들이 다음의 정수로 매핑 됨 ---> {}'.format(repr(text[:13]), text_as_int[:13]))

# 텍스트를 샘플 시퀀스로 나누기
len(text) % 101

# 단일 입력에 대해 원하는 문장의 최대 길이
seq_length = 100
examples_per_epoch = len(text) // seq_length
#훈련 샘플/타겟 만들기
char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int) #텍스트 벡터 -> 문자 인덱스 스트림으로 변환

for i in char_dataset.take(5):
    print(idx2char[i.numpy()])

sequences = char_dataset.batch(seq_length+1, drop_remainder=True)
# batch: 개별 문자들을 원하는 크기의 시퀀스로 쉽게 변환 할 수 있다.

for item in sequences.take(5):
  print(repr(''.join(idx2char[item.numpy()])))

string = 'First Citizen'

print(string[:-1])
print(string[1:])

def split_input_target(chunk):
  input_text = chunk[0:-1]
  target_text = chunk[1:]
  return input_text, target_text

dataset = sequences.map(split_input_target)
# map: 각 배치에 간단한 함수를 적용하고 입력 텍스트와 타깃 텍스트를 복사 및 이동한다.

for input_example, target_example in dataset.take(1):
  print('입력 데이터 : ', repr(''.join(idx2char[input_example.numpy()])))
  print('타깃 데이터 : ', repr(''.join(idx2char[target_example.numpy()])))

for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):
  print( " {:4d}단계".format(i))
  print(" 입력 : {} ({:s})".format(input_idx, repr(idx2char[input_idx])))
  print(" 예상 출력 : {} ({:s})".format(target_idx,  repr(idx2char[target_idx])))

"""## 훈련 배치 생성"""

BATCH_SIZE = 64

# 데이터셍를 섞을 버퍼 ㅡ기
BUFFER_SIZE = 10000

dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)
dataset

"""### 모델 설계"""

class Embedding:
    def __init__(self, input_dim, output_dim):
        self.table = np.random.randn(input_dim, output_dim)
    def __call__(self, x):
        # x : (batch, length) int
        batch, length = x.shape
        x = x.flatten()
        # (batch)
        y = self.table[x]
        y = y.reshape(batch, length, -1)
        return y

len(vocab)

x = np.random.randint(0, len(vocab), size=(3,100))
embedding = Embedding(len(vocab),512)
y = embedding(x)
print(y.shape)

# 문자로 된 어휘 사전의 크기
vocab_size = len(vocab)
print(vocab_size)

#임베딩 차원
embedding_dim = 256

#RNN 갯수
rnn_units = 1024

def build_model(vocab_size, embedding_dim, rnn_units, batch_size):
    model = tf.keras.Sequential([
                                 tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),
                                 tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),
                                 tf.keras.layers.Dense(vocab_size)
    ])
    return model

model = build_model(vocab_size = len(vocab),
                    embedding_dim = embedding_dim,
                    rnn_units = rnn_units,
                    batch_size=BATCH_SIZE)

"""## 모델 사용"""

# 출력 형태 살펴보기
for input_example_batch, target_example_batch in dataset.take(1):
  example_batch_predictions = model(input_example_batch)
  print(example_batch_predictions.shape, "# (배치크기, 시퀀스 길이, 어휘 사전 크기)")

model.summary(
)

# 배치의 첫 번째 샘플링
example_batch_predictions[0].shape

sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)
print(sampled_indices.shape)
sampled_indices= tf.squeeze(sampled_indices, axis=-1).numpy()
print(sampled_indices.shape)

sampled_indices

print("입력 : \n", repr("".join(idx2char[input_example_batch[0]])))
print()
print("예측된 다음 문자: \n", repr("".join(idx2char[sampled_indices])))

def loss(labels, logits):
  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)

example_batch_loss = loss(target_example_batch, example_batch_predictions)
print("예측 배열 크기(shape) :", example_batch_predictions.shape) 
print("스칼라 손실 :", example_batch_loss.numpy().mean())

model.compile(optimizer='adam',loss=loss)

# 체크포인트가 저장될 디렉토리
checkpoint_dir = './training_checkpoints'
# 체크포인트 파일 이름
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt_{epoch}")

checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_prefix,
    save_weights_only=True)

Epoch = 10
history = model.fit(dataset, epochs=Epoch, callbacks=[checkpoint_callback])

"""### 텍스트 생성"""

tf.train.latest_checkpoint(checkpoint_dir)

model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)
model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))
model.build(tf.TensorShape([1, None]))

model.summary()

def generate_text(model, start_string):
  #평가 단계 (학습된 모델을 사용하여 텍스트 생성)

  #생성할 문자의 수
  num_generate = 1000

  #시작 문자열을 숫자로 변환(벡터화)
  input_eval = [char2idx[s] for s in start_string]
  # (1 len(startr_string))
  input_eval = tf.expand_dims(input_eval, 0)

  #결과를 저장할 빈 문자열
  text_generated = []
  # 온도가 낮으면 더 에측 가능한 텍스트가 되고
  # 온도가 높으면 더 의외의 텍스트가 됩니다.
  # 최적의 세팅을 찾기 위한 실험
  temperature = 1.0

  #여기에서 배치 크기 ==1
  model.reset_states()
  for i in range(num_generate):
      predictions = model(input_eval)
      # 배치 차원 제거
      predictions = tf.squeeze(predictions, 0)

      #범주형 분포를 사용하여 모델에서 리턴한 단어 예측
      predictions = predictions/ temperature
      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()

      # 예측된 단어를 다음 입력으로 모델에 전달
      # 이전 은닉 상태와 함께
      input_eval = tf.expand_dims([predicted_id], 0)

      text_generated.append(idx2char[predicted_id])

  return (start_string + ''.join(text_generated))

print(generate_text(model, start_string=u"ROMEO: "))
#정확도를 높이고 싶으면 제일 쉬운 방법은 epoch 숫자를 늘리면 된다

"""# Seq2seq 모델 실습"""

#seq2seq는 인코더와 디코더로 이루어져 있다
import tensorflow as tf

class Encoder(tf.keras.Model):
  def __init__(self, vocab_size, embedding_dim, enc_units):
    super(Encoder, self).__init__()
    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
    self.lstm = tf.keras.layers.LSTM(enc_units)


  def call(self, x):
    print('입력 shape : ',x.shape)

    x = self.embedding(x)
    print("Embedding Layer를 거친 shape ", x.shape)

    output = self.lstm(x)
    print("LSTM shape의 output shape:", output.shape)


    return output

vocab_size = 30000
emb_size = 256
lstm_size = 512
batch_size = 1
sample_seq_len = 3

print("Vocab isze : {0}".format(vocab_size))
print("Embedding isze : {0}".format(emb_size))
print("LSTM isze : {0}".format(lstm_size))
print("Batch isze : {0}".format(batch_size))
print("Samnple sequence Length : {0}".format(sample_seq_len))

encoder = Encoder(vocab_size, emb_size,lstm_size )
sample_input = tf.zeros((batch_size,sample_seq_len))

sample_output = encoder(sample_input)

"""## LSTM Decoder"""

class Decoder(tf.keras.Model):
    def __init__(self, vocab_size, embedding_dim, dec_units):
        super(Decoder, self).__init__()
        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)
        self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences= True)
        self.fc = tf.keras.layers.Dense(vocab_size)
        self.softmax = tf.keras.layers.Softmax(axis=-1)

    def call(self, x, context_v):
        print("입력 shape :", x.shape)

        x = self.embedding(x)
        print("Embedding Layer을 거친 shape :", x.shape)

        context_v = tf.repeat(tf.expand_dims(context_v, axis=1), repeats=x.shape[1], axis=1)
        x = tf.concat([x, context_v], axis= -1)
        print("Context Vector가 더해진 shape :", x.shape)

        x = self.lstm(x)
        print("LSTM Layer의 Output layer:", x.shape)

        output = self.fc(x)
        print("Decoder의 최종 Output shape :", output.shape)

        return self.softmax(output)

vocab_size = 30000
emb_size = 256
lstm_size = 512
batch_size = 1
sample_seq_len = 3

print("Vocab isze : {0}".format(vocab_size))
print("Embedding isze : {0}".format(emb_size))
print("LSTM isze : {0}".format(lstm_size))
print("Batch isze : {0}".format(batch_size))
print("Samnple sequence Length : {0}".format(sample_seq_len))

decoder = Decoder(vocab_size, emb_size, lstm_size)
sample_input = tf.zeros((batch_size, sample_seq_len))

dec_output = decoder(sample_input, sample_output)

